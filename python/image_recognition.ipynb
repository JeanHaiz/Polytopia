{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from map_patching import map_patching_utils\n",
    "from score_recognition import score_recognition_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = score_recognition_utils.read_scores('../attachments/20211208_214922_918242881284751360.png')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"image30.jpg\", \"image31.jpg\"]\n",
    "patchwork = map_patching_utils.patch_partial_maps(files, \"example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"image41.jpg\", \"image40.jpg\"]\n",
    "patchwork = map_patching_utils.patch_partial_maps(files, \"winter&&storms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference_positions:\n",
    "\n",
    "top: (1121, 274)\n",
    "\n",
    "left: (105, 880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "# files = [\"image40.jpg\", \"image41.jpg\"]\n",
    "files = [\"image61.jpg\", \"image60.jpg\"]\n",
    "# files = [\"image30.jpg\", \"image31.jpg\"]\n",
    "# files = [\"image51.jpg\", \"image52.jpg\"]\n",
    "filename = \"combination_2.\"\n",
    "from utils import patch_partial_maps\n",
    "patch_partial_maps(files, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "root_path = \"/Users/jean/Documents/Coding/Polytopia/resources/\"\n",
    "image_path = root_path + \"bot_patch.png\"\n",
    "template_path = root_path + \"bot_patch_alpha.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\")\n",
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\")\n",
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)\n",
    "\n",
    "# Convert it to grayscale\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Store width and height of template in w and h\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# Perform match operations.\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Specify a threshold\n",
    "threshold = 0.2\n",
    " \n",
    "# Store the coordinates of matched area in a numpy array\n",
    "loc = np.where( res >= threshold)\n",
    " \n",
    "# Draw a rectangle around the matched region.\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,255,255), 2)\n",
    " \n",
    "# Show the final image with the matched area.\n",
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\", 0)   \n",
    "# Piece templates:\n",
    "img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "pawn_white_template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)\n",
    "\n",
    "w_pawn_white, h_pawn_white = pawn_white_template.shape[::-1]\n",
    "\n",
    "res_pawn_white = cv2.matchTemplate(img_gray,pawn_white_template,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "threshhold = 0.6\n",
    "loc = np.where(res_pawn_white >= threshhold)\n",
    "\n",
    "for pt in zip(*loc[::-1]):\n",
    "\tcv2.rectangle(img_rgb,pt,(pt[0]+w_pawn_white, pt[1]+h_pawn_white),(0,255,255),1)\n",
    "\n",
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected_2.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# read chessboard image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# read pawn image template\n",
    "template = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)\n",
    "hh, ww = template.shape[:2]\n",
    "\n",
    "# extract pawn base image and alpha channel and make alpha 3 channels\n",
    "pawn = template[:,:,0:3]\n",
    "template_alpha = template[:,:,3]\n",
    "cv2.imwrite(root_path + 'chessboard_alpha_1.png', template_alpha)\n",
    "alpha = cv2.merge([template_alpha,template_alpha,template_alpha])\n",
    "\n",
    "# do masked template matching and save correlation image\n",
    "correlation = cv2.matchTemplate(img, pawn, cv2.TM_CCORR, mask=alpha)\n",
    "\n",
    "# set threshold and get all matches\n",
    "threshhold = 0.95\n",
    "print(correlation.shape)\n",
    "print(np.max(correlation))\n",
    "loc = np.where(correlation >= threshhold)\n",
    "# print(loc[0], loc[1])\n",
    "# print([a for a in zip(*loc[::-1])])\n",
    "# draw matches \n",
    "result = img.copy()\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(result, pt, (pt[0]+ww, pt[1]+hh), (0,0,255), 1)\n",
    "    # print(pt)\n",
    "\n",
    "# save results\n",
    "cv2.imwrite(root_path + \"chessboard_correlation.png\", correlation)\n",
    "cv2.imwrite(root_path + 'chessboard_pawn.png', pawn)\n",
    "cv2.imwrite(root_path + 'chessboard_alpha.png', alpha)\n",
    "cv2.imwrite(root_path + 'chessboard_matches.jpg', result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# read chessboard image\n",
    "raw_img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "img = raw_img[:, :, 0:3]\n",
    "img_alpha = np.ones((raw_img.shape[0:2]))\n",
    "\n",
    "# read pawn image template\n",
    "template = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)\n",
    "hh, ww = template.shape[:2]\n",
    "\n",
    "# extract pawn base image and alpha channel and make alpha 3 channels\n",
    "pawn = template[:,:,0:3]\n",
    "alpha_template = template[:,:,3]\n",
    "alpha = cv2.merge([alpha_template,alpha_template,alpha_template])\n",
    "\n",
    "# set threshold\n",
    "# threshold = 0.99\n",
    "\n",
    "# do masked template matching and save correlation image\n",
    "corr_img = cv2.matchTemplate(img, pawn, cv2.TM_CCOEFF_NORMED, mask=alpha)\n",
    "cv2.imwrite('chessboard_correlation_2.png', corr_img)\n",
    "correlation_raw = (255*corr_img).clip(0,255).astype(np.uint8)\n",
    "cv2.imwrite('chessboard_correlation_3.png', correlation_raw)\n",
    "# search for max score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(alpha_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize = 31\n",
    "blur = cv2.GaussianBlur(correlation_raw, (ksize, ksize), 25)\n",
    "cv2.imwrite('chessboard_blur.jpg', blur)\n",
    "np.max(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 40\n",
    "print(blur.shape)\n",
    "print(np.max(blur))\n",
    "loc = np.where(blur >= threshhold)\n",
    "# print(loc[0], loc[1])\n",
    "# print([a for a in zip(*loc[::-1])])\n",
    "# draw matches \n",
    "result = img.copy()\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(result, pt, (pt[0]+ww, pt[1]+hh), (0,0,255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 40\n",
    "result = img.copy()\n",
    "max_val = np.max(blur)\n",
    "rad = int(math.sqrt(hh*hh+ww*ww)/4)\n",
    "\n",
    "while max_val > threshold:\n",
    "\n",
    "    # find max value of correlation image\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(blur)\n",
    "    # print(max_val, max_loc)\n",
    "\n",
    "    if max_val > threshold:\n",
    "        # draw match on copy of input\n",
    "        # cv2.rectangle(result, max_loc, (max_loc[0]+ww, max_loc[1]+hh), (0,0,255), 2)\n",
    "        img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] = img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] - alpha_template / 255.0\n",
    "\n",
    "        # write black circle at max_loc in corr_img\n",
    "        cv2.circle(blur, (max_loc), radius=rad, color=0, thickness=cv2.FILLED)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(np.min(img_alpha), np.max(img_alpha))\n",
    "#correlation = (255*blur).clip(0,255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"img_alpha.png\", (255*img_alpha).clip(0,255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape, img_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = np.reshape(img_alpha, [img_alpha.shape[0], img_alpha.shape[1], 1])\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_255 = (255*reshaped).clip(0,255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.merge([img_alpha_c, img_alpha_c, img_alpha_c]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dtype, img_alpha_c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha_c.shape, result.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha_c = img_alpha.clip(0,1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha_c.shape[0] * img_alpha_c.shape[1] - np.sum(img_alpha_c == 1.0) - np.sum(img_alpha_c == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = cv2.multiply(result, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"masked.png\", masked)\n",
    "cv2.imwrite(\"result_for_mask.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_alpha = np.concatenate((result, reshaped_255), axis=2)\n",
    "print(with_alpha.shape)\n",
    "cv2.imwrite(\"with_alpha.png\", with_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save results\n",
    "cv2.imwrite('chessboard_pawn.png', pawn)\n",
    "cv2.imwrite('chessboard_alpha.png', alpha)\n",
    "cv2.imwrite('chessboard_correlation.png', blur)\n",
    "cv2.imwrite('chessboard_matches2.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/jean/Documents/Coding/Polytopia/resources/\"\n",
    "\n",
    "image_filename = \"image12\"\n",
    "image_path = root_path + image_filename + \".png\"\n",
    "template_path = root_path + \"bot_patch_alpha.png\"\n",
    "\n",
    "from map_patching import map_patching_utils\n",
    "\n",
    "map_patching_utils.remove_clouds(image_path, template_path, image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_patching.map_patching_utils import *\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/python/resources/semi/INPUT/f0af9f77-40b6-473f-b60e-11602261794e.png\"\n",
    "\n",
    "image = image_utils.get_background_template() # cv2.imread(path)\n",
    "edges = get_three_color_edges(image)\n",
    "blur = cv2.GaussianBlur(edges, (15, 15), sigmaX=25)\n",
    "contour = select_contours(blur)\n",
    "polygon = draw_contour(edges, contour)\n",
    "vertices_i = compute_vertices(polygon)\n",
    "lines = get_lines([p[0] for p in polygon])\n",
    "\n",
    "cv2.drawContours(edges, [contour], 0, (255, 255, 255), 3)\n",
    "cv2.imwrite(\"background_overlay.png\", edges)\n",
    "# lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in lines.iterrows():\n",
    "\tl = row[1]\n",
    "\tcv2.line(edges, l[5], l[6], (255, 255, 255), 5)\n",
    "cv2.imwrite(\"lines_blured.png\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_contours(image, filename=None):\n",
    "    image = image.copy()\n",
    "    keepers = []\n",
    "    for mode in [cv2.RETR_TREE, cv2.RETR_EXTERNAL, cv2.RETR_LIST, cv2.RETR_CCOMP]:\n",
    "        for method in [cv2.CHAIN_APPROX_NONE, cv2.CHAIN_APPROX_SIMPLE]:\n",
    "            contours, hierarchy = cv2.findContours(image.copy(), mode, cv2.CHAIN_APPROX_NONE)\n",
    "            hierarchy = hierarchy[0]\n",
    "\n",
    "            for index_, contour_ in enumerate(contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(contour_)\n",
    "\n",
    "                \n",
    "                if w > int(image.shape[0] / 2) and h > int(image.shape[1] / 4):\n",
    "                    keepers.append([mode, method, index_, contour_, [x, y, w, h]])\n",
    "\n",
    "\n",
    "            print(len(keepers))\n",
    "\n",
    "            for i, k in enumerate(keepers):\n",
    "                contours = edges.copy()\n",
    "                cv2.drawContours(contours, [k[3]], 0, (255, 255, 255), 3)\n",
    "                cv2.imwrite(\"contours/contours_check_%s_%s_%s_.png\" % (mode, method, i), contours)\n",
    "            # print(\"#contours kept: %d\" % len(keepers))\n",
    "    \n",
    "    keepers.sort(key=lambda k: -(k[4][2] + k[4][3])) \n",
    "    return keepers[0]\n",
    "select_contours(blur) #Â edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(edges, (15, 15), sigmaX=25)\n",
    "cv2.imwrite(\"contours/blur.png\", blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([cv2.RETR_TREE, cv2.RETR_EXTERNAL, cv2.RETR_LIST, cv2.RETR_CCOMP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_utils.get_background_template().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"resources/ps11w4-winterstorms_plague-e99769/SCORE_INPUT/d298761e-a93a-415c-8588-d0011422af1c.png\")\n",
    "cropped = crop(image)\n",
    "score_text = read(image)\n",
    "# print(score_text)\n",
    "clear = clear_noise(cropped.copy())  # , low_threshold, high_threshold, blur_kernel, min_size)\n",
    "score_text_you = read(clear)\n",
    "\n",
    "output = [read_line(a) for a in score_text.split(\"\\n\") if \"score\" in a] + [read_line(a) for a in score_text_you.split(\"\\n\") if \"score\" in a and \"Ruled by you\" in a]\n",
    "# for min_size in [15, 50, 100, 500]:\n",
    "\t# for low_threshold in [0, 50, 100, 150, 200]:\n",
    "\t\t# for high_threshold in [150, 200, 250]:\n",
    "\t\t\t# if high_threshold > low_threshold:\n",
    "\t\t\t\t# for blur_kernel in [None, 1, 2, 5, 10]:\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# if output == ['Ruled by ZeBiggestPotato, score: 6,285 points', 'Unknown ruler, score: 4,045 points', 'Ruled by Samaterribl, score: 3,315 points', 'Ruled by you, score: 4,060 points']:\n",
    "\t\t\t\t\t\t# if \"ZeBiggestPotato\" in score_text and \"6,285\" in score_text and \"Ruled by you\" in score_text:\n",
    "\t\t\t\t\t\t# print(min_size, low_threshold, high_threshold, blur_kernel)\n",
    "# scores = get_scores(clear)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = crop(image)\n",
    "clear = clear_noise(cropped, low_threshold, high_threshold, blur_kernel)\n",
    "score_text_you = read(clear)\n",
    "score_text = read(image)\n",
    "if \"ZeBiggestPotato\" in score_text and \"6,285\" in score_text and \"Ruled by you\" in score_text_you:\n",
    "\tprint(\"yes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([a for a in score_text.split(\"\\n\") if \"score\" in a])\n",
    "print([a for a in score_text_you.split(\"\\n\") if \"score\" in a and \"Ruled by you\" in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"resources/ps11w4-winterstorms_plague-e99769/SCORE_INPUT/d298761e-a93a-415c-8588-d0011422af1c.png\")\n",
    "cropped = crop(image)\n",
    "blur_kernel=1\n",
    "blur = cv2.blur(cropped, (blur_kernel, blur_kernel))\n",
    "score_text = read(blur, config='--oem 1')\n",
    "score_text = score_text.replace(\".\", \"\").replace(\" \", \"\")\n",
    "print([read_line(a) for a in score_text.split(\"\\n\") if \"score\" in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line(line):\n",
    "    # print(\"line\", line)\n",
    "    s1 = line.split(\",\")\n",
    "    if len(s1) >= 2:\n",
    "        if \"Unknownruler\" in s1[0].strip() or \"Ruledbyyou\" in s1[0].strip():\n",
    "            player = s1[0]\n",
    "        else:\n",
    "            player = s1[0].strip().split(\" \")[-1]\n",
    "\n",
    "        if player is not None:\n",
    "            player = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", player)\n",
    "\n",
    "        s2 = \"\".join(s1[1:]).split(\":\")\n",
    "        if len(s2) >= 2:\n",
    "            score = int(s2[1].split(\"points\")[0].replace(\",\", \"\"))\n",
    "        else:\n",
    "            print(\"s2 error\", line)\n",
    "            return\n",
    "    else:\n",
    "        print(\"s1 error\", line)\n",
    "        return\n",
    "    return (player, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"resources/ps11w4-winterstorms_plague-e99769/SCORE_INPUT/d298761e-a93a-415c-8588-d0011422af1c.png\")\n",
    "read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/python/resources/polytopia-helper-testing/SCORE_INPUT/9be6bc84-6b45-40a3-a3eb-062b65717336.png\")\n",
    "# score_image = crop(image)\n",
    "read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.image_to_string(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"header.png\", header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for path in [\n",
    "\t\"/Users/jean/Documents/Coding/Polytopia/python/resources/ps11w4-winterstorms_plague-e99769/MAP_INPUT/df3e5aa2-8f13-4a3c-9908-c8ec98d149d6.png\", \n",
    "\t\"/Users/jean/Documents/Coding/Polytopia/python/resources/ps11w4-winterstorms_plague-e99769/MAP_INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png\", \n",
    "\t\"/Users/jean/Documents/Coding/Polytopia/python/resources/ps11w4-winterstorms_plague-e99769/MAP_INPUT/0ec21a58-acd4-4d8a-a2bc-d047547d7f5b.png\"]:\n",
    "\timage = cv2.imread(path)\n",
    "\tcrop = image[:int(image.shape[0] / 6), :]\n",
    "\tgrayImage = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "\t# blur_kernel = 2\n",
    "\t# blur = cv2.blur(grayImage, (blur_kernel, blur_kernel))\n",
    "\t(thresh, blackAndWhiteImage) = cv2.threshold(grayImage, 100, 255, cv2.THRESH_BINARY)\n",
    "\tselected_image = blackAndWhiteImage\n",
    "\t# map_text = pytesseract.image_to_string(selected_image, config='--oem 3 --psm 6').split(\"\\n\")\n",
    "\t\n",
    "\tcontours, hierarchy = cv2.findContours(selected_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\trows = {}\n",
    "\trow_mins = {}\n",
    "\trow_maxes = {}\n",
    "\n",
    "\tfor c in contours:\n",
    "\t\tconvex_hull = cv2.convexHull(c, returnPoints=True)\n",
    "\t\t(y,x,h,w) = cv2.boundingRect(c)\n",
    "\t\tif w > 10 and h > 10:\n",
    "\t\t\tfound_row = False\n",
    "\t\t\tfor i in rows.keys():\n",
    "\t\t\t\tif found_row == False:\n",
    "\t\t\t\t\trow_min_i = row_mins[i]\n",
    "\t\t\t\t\trow_max_i = row_maxes[i]\n",
    "\t\t\t\t\tif x >= row_min_i and x + w <= row_max_i:\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\t\t\t\t\telif x >= row_min_i and x <= row_max_i and x + w >= row_max_i:\n",
    "\t\t\t\t\t\trow_max_i = x + w\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\t\t\t\t\telif x <= row_min_i and x + w >= row_min_i and x + w <= row_max_i:\n",
    "\t\t\t\t\t\trow_min_i = x\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\t\t\t\t\telif x <= row_min_i and x + w >= row_max_i:\n",
    "\t\t\t\t\t\trow_min_i = x\n",
    "\t\t\t\t\t\trow_max_i = x + w\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\n",
    "\t\t\t# cv2.rectangle(selected_image, (y,x), (y+h, x+w), (255, 0, 0), 2)\n",
    "\t\t\t# cv2.drawContours(selected_image, [convex_hull], 0, (255, 255, 255), 3)\n",
    "\t\t\n",
    "\t\t\tif not found_row:\n",
    "\t\t\t\tnew_i = len(rows.keys())\n",
    "\t\t\t\trows[new_i] = [c]\n",
    "\t\t\t\trow_mins[new_i] = x\n",
    "\t\t\t\trow_maxes[new_i] = x + w\n",
    "\t\n",
    "\tdelta = 15\n",
    "\tfound_turn = False\n",
    "\tfor i in rows.keys():\n",
    "\t\t# print(i, row_mins[i], row_maxes[i])\n",
    "\t\trow_min_i = max(row_mins[i] - delta, 0)\n",
    "\t\trow_max_i = min(row_maxes[i] + delta, selected_image.shape[0])\n",
    "\t\trow_image = selected_image[row_min_i:row_max_i]\n",
    "\t\tcv2.imwrite(\"binary_%d.png\" % i, row_image)\n",
    "\t\trow_text = pytesseract.image_to_string(row_image, config='--psm 6')\n",
    "\t\tcleared_row_text = row_text.replace(\"\\n\", \"\").replace(\"\\x0c\", \"\").split(\" \")\n",
    "\t\tif len(row_text) > 2 and row_text[2].isnumeric():\n",
    "\t\t\tturn = row_text[2]\n",
    "\t\t\tprint(turn, found_turn, path)\n",
    "\t\t\tfound_turn = True\n",
    "\tif not found_turn:\n",
    "\t\tprint(\"not found\", len(rows.keys()), path)\n",
    "\t\t# cv2.imwrite(\"gray.png\", grayImage)\n",
    "\t\t# cv2.imwrite(\"binary.png\", blackAndWhiteImage)\n",
    "\t\n",
    "\tif False: # and len(map_text) <= 1 or len(map_text[1].split(\" \")) <= 2 or map_text[1].split(\" \")[2] != \"11\":\n",
    "\t\tfor i in rows.keys():\n",
    "\t\t\t# print(i, row_mins[i], row_maxes[i])\n",
    "\t\t\trow_min_i = max(row_mins[i] - delta, 0)\n",
    "\t\t\trow_max_i = min(row_maxes[i] + delta, selected_image.shape[0])\n",
    "\t\t\trow_image = selected_image[row_min_i:row_max_i]\n",
    "\t\t\tcv2.imwrite(\"binary_%d.png\" % i, row_image)\n",
    "\t\t\trow_text = pytesseract.image_to_string(row_image, config='--psm 6').split(\" \")\n",
    "\t\t\tif len(row_text) > 2 and row_text[2].isnumeric():\n",
    "\t\t\t\tprint(row_text[2])\n",
    "\t\t# print(row_mins, row_maxes)\n",
    "\t\tcv2.imwrite(\"gray.png\", grayImage)\n",
    "\t\tcv2.imwrite(\"blur.png\", blur)\n",
    "\t\tcv2.imwrite(\"binary.png\", blackAndWhiteImage)\n",
    "\t\tprint(path)\n",
    "\t\tprint(map_text)\n",
    "\t\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"gray.png\", grayImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"binary.png\", blackAndWhiteImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jean/Documents/Coding/Polytopia/python\n",
      "map_patching_utils background\n",
      "size for i 0 (1062, 1561, 3) <class 'numpy.ndarray'>\n",
      "simplified contour has 9 points with epsilon= 17.43221502006054\n",
      "mask area: 18 M\n",
      "vertices:\n",
      " [[ 890  101]\n",
      " [ 872 1017]\n",
      " [ 162  529]\n",
      " [1604  529]]\n",
      "orientation True 1.574235807860262\n",
      "all lines\n",
      "    0       1         2  3  4            5            6\n",
      "0  0   22133  0.423358  1  1   [890, 101]  [1027, 159]\n",
      "1  1  469829  0.641248  1  1  [1027, 159]  [1604, 529]\n",
      "2  2    3600  0.000000  0  1  [1604, 529]  [1604, 589]\n",
      "3  3  472141 -0.639033 -1  1  [1604, 589]  [1025, 959]\n",
      "4  4   26773 -0.379085 -1  1  [1025, 959]  [872, 1017]\n",
      "5  5  650557  0.592219 -1 -1  [872, 1017]   [178, 606]\n",
      "6  6    6185  4.812500 -1 -1   [178, 606]   [162, 529]\n",
      "7  7  317648 -0.652542  1 -1   [162, 529]   [634, 221]\n",
      "8  8   79936 -0.468750  1 -1   [634, 221]   [890, 101]\n",
      "filtered lines\n",
      "        0       1         2  3  4            5            6\n",
      "3  4                                                      \n",
      "-1 -1  5  650557  0.592219 -1 -1  [872, 1017]   [178, 606]\n",
      "    1  3  472141 -0.639033 -1  1  [1604, 589]  [1025, 959]\n",
      " 1 -1  7  317648 -0.652542  1 -1   [162, 529]   [634, 221]\n",
      "    1  1  469829  0.641248  1  1  [1027, 159]  [1604, 529]\n",
      "[[107, 564], [1650, 559]]\n",
      "\n",
      "intersections:\n",
      " [[107, 564], [1650, 559]]\n",
      "vertices after:\n",
      " [[ 890  101]\n",
      " [ 872 1017]\n",
      " [ 107  564]\n",
      " [1650  559]]\n",
      "map_patching_utils 22c03726-5e39-46aa-ad7b-fb247aa5c9d7\n",
      "Image valid 1792\n",
      "size for i 1 (1792, 828, 3) <class 'numpy.ndarray'>\n",
      "simplified contour has 8 points with epsilon= 11.079564454555511\n",
      "mask area: 8 M\n",
      "vertices:\n",
      " [[ 676  678]\n",
      " [ 657 1353]\n",
      " [ 135  997]\n",
      " [ 885 1224]]\n",
      "orientation True 1.1111111111111112\n",
      "all lines\n",
      "    0       1           2  3  4            5            6\n",
      "0  0   59393    0.610577  1  1   [676, 678]   [884, 805]\n",
      "1  1  175562  419.000000  1  1   [884, 805]  [885, 1224]\n",
      "2  2   68625   -0.565789 -1  1  [885, 1224]  [657, 1353]\n",
      "3  3   58570    0.470320 -1 -1  [657, 1353]  [438, 1250]\n",
      "4  4  123885    0.680412 -1 -1  [438, 1250]  [147, 1052]\n",
      "5  5    3169    4.583333 -1 -1  [147, 1052]   [135, 997]\n",
      "6  6  349730   -0.618290  1 -1   [135, 997]   [638, 686]\n",
      "7  7    1508   -0.210526  1 -1   [638, 686]   [676, 678]\n",
      "filtered lines\n",
      "        0       1         2  3  4            5            6\n",
      "3  4                                                      \n",
      "-1 -1  4  123885  0.680412 -1 -1  [438, 1250]  [147, 1052]\n",
      "    1  2   68625 -0.565789 -1  1  [885, 1224]  [657, 1353]\n",
      " 1 -1  6  349730 -0.618290  1 -1   [135, 997]   [638, 686]\n",
      "    1  0   59393  0.610577  1  1   [676, 678]   [884, 805]\n",
      "[[98, 1018], [1240, 1023]]\n",
      "\n",
      "intersections:\n",
      " [[98, 1018], [1240, 1023]]\n",
      "vertices after:\n",
      " [[ 676  678]\n",
      " [ 657 1353]\n",
      " [  98 1018]\n",
      " [1240 1023]]\n",
      "top-bottom ref:  True 0.593648736228127\n",
      "reference position:  [783, 463]\n",
      "reference size:  [1566, 916]\n",
      "scale factor: 1.0\n",
      "padding: [-57, 412]\n",
      "cropped and scaled vertices:\n",
      " [[833, 513], [815, 1429], [50, 976], [1593, 971]]\n",
      "sizes: (1062, 1561, 3) (1062, 1504, 3)\n",
      "scale factor: 0.7368995633187773\n",
      "padding: [-66, -389]\n",
      "cropped and scaled vertices:\n",
      " [[851, 531], [825, 1447], [66, 992], [1616, 999]]\n",
      "sizes: (2431, 1123, 3) (2042, 1057, 3)\n",
      "output size: [2431 1561]\n",
      "(1062, 1561, 3) (1062, 1504, 3)\n",
      "scaled_padding [412   0]\n",
      "size (1062, 1561)\n",
      "bit size (1062, 1561, 3)\n",
      "(2431, 1123, 3) (2042, 1057, 3)\n",
      "scaled_padding [0 0]\n",
      "size (2431, 1123)\n",
      "bit size (2431, 1123, 3)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ks/8tknm8f96kz76nccrfvhbd4w0000gn/T/ipykernel_54376/2853594440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# channel_name = 'polytopia-helper-testing'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mchannel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"eli-jl-host-game-14\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mpatch_partial_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"196\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Coding/Polytopia/python/map_patching/map_patching_utils.py\u001b[0m in \u001b[0;36mpatch_partial_maps\u001b[0;34m(channel_name, files, map_size, database_client, message)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0moppacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransparency_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mpatch_work\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mpatch_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moppacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Coding/Polytopia/python/map_patching/map_patching_utils.py\u001b[0m in \u001b[0;36mpatch_output\u001b[0;34m(patch_work, scaled_padding, oppacity, size, bit, i)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moppacity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moppacity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;31m# result = cv2.multiply(bit, oppacity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mpatch_work\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscaled_padding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscaled_padding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_padding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscaled_padding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "from map_patching.map_patching_utils import patch_partial_maps\n",
    "\n",
    "# files = [\"3c3581aa-48fe-479a-9f82-8916cdcf2704\", \"1843f954-6e67-4aee-a493-f63f1043785c\"]\n",
    "# files = ['13bd77f1-9b3b-455e-b24f-43b0b0e726e2', '1d5c103a-3ce3-42d7-b16e-308b045e75b6', '6ad460f2-4673-4ed6-901e-4c1e0bf5cf69', '91dfdfdf-f7c0-4175-aab0-161b6da704b4']\n",
    "files = [\"22c03726-5e39-46aa-ad7b-fb247aa5c9d7\"]\n",
    "# channel_name = 'polytopia-helper-testing'\n",
    "channel_name = \"eli-jl-host-game-14\"\n",
    "await patch_partial_maps(channel_name, files, \"196\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
