{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from map_patching import map_patching_utils\n",
    "from score_recognition import score_recognition_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = score_recognition_utils.read_scores('../attachments/20211208_214922_918242881284751360.png')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"image30.jpg\", \"image31.jpg\"]\n",
    "patchwork = map_patching_utils.patch_partial_maps(files, \"example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"image41.jpg\", \"image40.jpg\"]\n",
    "patchwork = map_patching_utils.patch_partial_maps(files, \"winter&&storms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference_positions:\n",
    "\n",
    "top: (1121, 274)\n",
    "\n",
    "left: (105, 880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "# files = [\"image40.jpg\", \"image41.jpg\"]\n",
    "files = [\"image61.jpg\", \"image60.jpg\"]\n",
    "# files = [\"image30.jpg\", \"image31.jpg\"]\n",
    "# files = [\"image51.jpg\", \"image52.jpg\"]\n",
    "filename = \"combination_2.\"\n",
    "from utils import patch_partial_maps\n",
    "patch_partial_maps(files, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "root_path = \"/Users/jean/Documents/Coding/Polytopia/resources/\"\n",
    "image_path = root_path + \"bot_patch.png\"\n",
    "template_path = root_path + \"bot_patch_alpha.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\")\n",
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\")\n",
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)\n",
    "\n",
    "# Convert it to grayscale\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Store width and height of template in w and h\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# Perform match operations.\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Specify a threshold\n",
    "threshold = 0.2\n",
    " \n",
    "# Store the coordinates of matched area in a numpy array\n",
    "loc = np.where( res >= threshold)\n",
    " \n",
    "# Draw a rectangle around the matched region.\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,255,255), 2)\n",
    " \n",
    "# Show the final image with the matched area.\n",
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\", 0)   \n",
    "# Piece templates:\n",
    "img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "pawn_white_template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)\n",
    "\n",
    "w_pawn_white, h_pawn_white = pawn_white_template.shape[::-1]\n",
    "\n",
    "res_pawn_white = cv2.matchTemplate(img_gray,pawn_white_template,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "threshhold = 0.6\n",
    "loc = np.where(res_pawn_white >= threshhold)\n",
    "\n",
    "for pt in zip(*loc[::-1]):\n",
    "\tcv2.rectangle(img_rgb,pt,(pt[0]+w_pawn_white, pt[1]+h_pawn_white),(0,255,255),1)\n",
    "\n",
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected_2.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# read chessboard image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# read pawn image template\n",
    "template = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)\n",
    "hh, ww = template.shape[:2]\n",
    "\n",
    "# extract pawn base image and alpha channel and make alpha 3 channels\n",
    "pawn = template[:,:,0:3]\n",
    "template_alpha = template[:,:,3]\n",
    "cv2.imwrite(root_path + 'chessboard_alpha_1.png', template_alpha)\n",
    "alpha = cv2.merge([template_alpha,template_alpha,template_alpha])\n",
    "\n",
    "# do masked template matching and save correlation image\n",
    "correlation = cv2.matchTemplate(img, pawn, cv2.TM_CCORR, mask=alpha)\n",
    "\n",
    "# set threshold and get all matches\n",
    "threshhold = 0.95\n",
    "print(correlation.shape)\n",
    "print(np.max(correlation))\n",
    "loc = np.where(correlation >= threshhold)\n",
    "# print(loc[0], loc[1])\n",
    "# print([a for a in zip(*loc[::-1])])\n",
    "# draw matches \n",
    "result = img.copy()\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(result, pt, (pt[0]+ww, pt[1]+hh), (0,0,255), 1)\n",
    "    # print(pt)\n",
    "\n",
    "# save results\n",
    "cv2.imwrite(root_path + \"chessboard_correlation.png\", correlation)\n",
    "cv2.imwrite(root_path + 'chessboard_pawn.png', pawn)\n",
    "cv2.imwrite(root_path + 'chessboard_alpha.png', alpha)\n",
    "cv2.imwrite(root_path + 'chessboard_matches.jpg', result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# read chessboard image\n",
    "raw_img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "img = raw_img[:, :, 0:3]\n",
    "img_alpha = np.ones((raw_img.shape[0:2]))\n",
    "\n",
    "# read pawn image template\n",
    "template = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)\n",
    "hh, ww = template.shape[:2]\n",
    "\n",
    "# extract pawn base image and alpha channel and make alpha 3 channels\n",
    "pawn = template[:,:,0:3]\n",
    "alpha_template = template[:,:,3]\n",
    "alpha = cv2.merge([alpha_template,alpha_template,alpha_template])\n",
    "\n",
    "# set threshold\n",
    "# threshold = 0.99\n",
    "\n",
    "# do masked template matching and save correlation image\n",
    "corr_img = cv2.matchTemplate(img, pawn, cv2.TM_CCOEFF_NORMED, mask=alpha)\n",
    "cv2.imwrite('chessboard_correlation_2.png', corr_img)\n",
    "correlation_raw = (255*corr_img).clip(0,255).astype(np.uint8)\n",
    "cv2.imwrite('chessboard_correlation_3.png', correlation_raw)\n",
    "# search for max score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(alpha_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize = 31\n",
    "blur = cv2.GaussianBlur(correlation_raw, (ksize, ksize), 25)\n",
    "cv2.imwrite('chessboard_blur.jpg', blur)\n",
    "np.max(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 40\n",
    "print(blur.shape)\n",
    "print(np.max(blur))\n",
    "loc = np.where(blur >= threshhold)\n",
    "# print(loc[0], loc[1])\n",
    "# print([a for a in zip(*loc[::-1])])\n",
    "# draw matches \n",
    "result = img.copy()\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(result, pt, (pt[0]+ww, pt[1]+hh), (0,0,255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 40\n",
    "result = img.copy()\n",
    "max_val = np.max(blur)\n",
    "rad = int(math.sqrt(hh*hh+ww*ww)/4)\n",
    "\n",
    "while max_val > threshold:\n",
    "\n",
    "    # find max value of correlation image\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(blur)\n",
    "    # print(max_val, max_loc)\n",
    "\n",
    "    if max_val > threshold:\n",
    "        # draw match on copy of input\n",
    "        # cv2.rectangle(result, max_loc, (max_loc[0]+ww, max_loc[1]+hh), (0,0,255), 2)\n",
    "        img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] = img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] - alpha_template / 255.0\n",
    "\n",
    "        # write black circle at max_loc in corr_img\n",
    "        cv2.circle(blur, (max_loc), radius=rad, color=0, thickness=cv2.FILLED)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(np.min(img_alpha), np.max(img_alpha))\n",
    "#correlation = (255*blur).clip(0,255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"img_alpha.png\", (255*img_alpha).clip(0,255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape, img_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = np.reshape(img_alpha, [img_alpha.shape[0], img_alpha.shape[1], 1])\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_255 = (255*reshaped).clip(0,255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.merge([img_alpha_c, img_alpha_c, img_alpha_c]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dtype, img_alpha_c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha_c.shape, result.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha_c = img_alpha.clip(0,1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpha_c.shape[0] * img_alpha_c.shape[1] - np.sum(img_alpha_c == 1.0) - np.sum(img_alpha_c == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = cv2.multiply(result, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"masked.png\", masked)\n",
    "cv2.imwrite(\"result_for_mask.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_alpha = np.concatenate((result, reshaped_255), axis=2)\n",
    "print(with_alpha.shape)\n",
    "cv2.imwrite(\"with_alpha.png\", with_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save results\n",
    "cv2.imwrite('chessboard_pawn.png', pawn)\n",
    "cv2.imwrite('chessboard_alpha.png', alpha)\n",
    "cv2.imwrite('chessboard_correlation.png', blur)\n",
    "cv2.imwrite('chessboard_matches2.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/jean/Documents/Coding/Polytopia/resources/\"\n",
    "\n",
    "image_filename = \"image12\"\n",
    "image_path = root_path + image_filename + \".png\"\n",
    "template_path = root_path + \"bot_patch_alpha.png\"\n",
    "\n",
    "from map_patching import map_patching_utils\n",
    "\n",
    "map_patching_utils.remove_clouds(image_path, template_path, image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_patching.map_patching_utils import *\n",
    "from common import image_processing_utils\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/src/resources/semi/INPUT/f0af9f77-40b6-473f-b60e-11602261794e.png\"\n",
    "\n",
    "image = image_utils.get_background_template() # cv2.imread(path)\n",
    "edges = image_processing_utils.get_three_color_edges(image, border=50)\n",
    "blur = cv2.GaussianBlur(edges, (15, 15), sigmaX=25)\n",
    "contour = select_contours(blur)\n",
    "polygon = draw_contour(edges, contour)\n",
    "vertices_i = compute_vertices(polygon)\n",
    "lines = get_lines([p[0] for p in polygon])\n",
    "\n",
    "cv2.drawContours(edges, [contour], 0, (255, 255, 255), 3)\n",
    "cv2.imwrite(\"background_overlay.png\", edges)\n",
    "# lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in lines.iterrows():\n",
    "\tl = row[1]\n",
    "\tcv2.line(edges, l[5], l[6], (255, 255, 255), 5)\n",
    "cv2.imwrite(\"lines_blured.png\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_contours(image, filename=None):\n",
    "    image = image.copy()\n",
    "    keepers = []\n",
    "    for mode in [cv2.RETR_TREE, cv2.RETR_EXTERNAL, cv2.RETR_LIST, cv2.RETR_CCOMP]:\n",
    "        for method in [cv2.CHAIN_APPROX_NONE, cv2.CHAIN_APPROX_SIMPLE]:\n",
    "            contours, hierarchy = cv2.findContours(image.copy(), mode, cv2.CHAIN_APPROX_NONE)\n",
    "            hierarchy = hierarchy[0]\n",
    "\n",
    "            for index_, contour_ in enumerate(contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(contour_)\n",
    "\n",
    "                \n",
    "                if w > int(image.shape[0] / 2) and h > int(image.shape[1] / 4):\n",
    "                    keepers.append([mode, method, index_, contour_, [x, y, w, h]])\n",
    "\n",
    "\n",
    "            print(len(keepers))\n",
    "\n",
    "            for i, k in enumerate(keepers):\n",
    "                contours = edges.copy()\n",
    "                cv2.drawContours(contours, [k[3]], 0, (255, 255, 255), 3)\n",
    "                cv2.imwrite(\"contours/contours_check_%s_%s_%s_.png\" % (mode, method, i), contours)\n",
    "            # print(\"#contours kept: %d\" % len(keepers))\n",
    "    \n",
    "    keepers.sort(key=lambda k: -(k[4][2] + k[4][3])) \n",
    "    return keepers[0]\n",
    "select_contours(blur) # edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(edges, (15, 15), sigmaX=25)\n",
    "cv2.imwrite(\"contours/blur.png\", blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([cv2.RETR_TREE, cv2.RETR_EXTERNAL, cv2.RETR_LIST, cv2.RETR_CCOMP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_utils.get_background_template().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"resources/ps11w4-winterstorms_plague-e99769/SCORE_INPUT/d298761e-a93a-415c-8588-d0011422af1c.png\")\n",
    "cropped = crop(image)\n",
    "score_text = read(image)\n",
    "# print(score_text)\n",
    "clear = clear_noise(cropped.copy())  # , low_threshold, high_threshold, blur_kernel, min_size)\n",
    "score_text_you = read(clear)\n",
    "\n",
    "output = [read_line(a) for a in score_text.split(\"\\n\") if \"score\" in a] + [read_line(a) for a in score_text_you.split(\"\\n\") if \"score\" in a and \"Ruled by you\" in a]\n",
    "# for min_size in [15, 50, 100, 500]:\n",
    "\t# for low_threshold in [0, 50, 100, 150, 200]:\n",
    "\t\t# for high_threshold in [150, 200, 250]:\n",
    "\t\t\t# if high_threshold > low_threshold:\n",
    "\t\t\t\t# for blur_kernel in [None, 1, 2, 5, 10]:\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# if output == ['Ruled by ZeBiggestPotato, score: 6,285 points', 'Unknown ruler, score: 4,045 points', 'Ruled by Samaterribl, score: 3,315 points', 'Ruled by you, score: 4,060 points']:\n",
    "\t\t\t\t\t\t# if \"ZeBiggestPotato\" in score_text and \"6,285\" in score_text and \"Ruled by you\" in score_text:\n",
    "\t\t\t\t\t\t# print(min_size, low_threshold, high_threshold, blur_kernel)\n",
    "# scores = get_scores(clear)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = crop(image)\n",
    "clear = clear_noise(cropped, low_threshold, high_threshold, blur_kernel)\n",
    "score_text_you = read(clear)\n",
    "score_text = read(image)\n",
    "if \"ZeBiggestPotato\" in score_text and \"6,285\" in score_text and \"Ruled by you\" in score_text_you:\n",
    "\tprint(\"yes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([a for a in score_text.split(\"\\n\") if \"score\" in a])\n",
    "print([a for a in score_text_you.split(\"\\n\") if \"score\" in a and \"Ruled by you\" in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"resources/ps11w4-winterstorms_plague-e99769/SCORE_INPUT/d298761e-a93a-415c-8588-d0011422af1c.png\")\n",
    "cropped = crop(image)\n",
    "blur_kernel=1\n",
    "blur = cv2.blur(cropped, (blur_kernel, blur_kernel))\n",
    "score_text = read(blur, config='--oem 1')\n",
    "score_text = score_text.replace(\".\", \"\").replace(\" \", \"\")\n",
    "print([read_line(a) for a in score_text.split(\"\\n\") if \"score\" in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line(line):\n",
    "    # print(\"line\", line)\n",
    "    s1 = line.split(\",\")\n",
    "    if len(s1) >= 2:\n",
    "        if \"Unknownruler\" in s1[0].strip() or \"Ruledbyyou\" in s1[0].strip():\n",
    "            player = s1[0]\n",
    "        else:\n",
    "            player = s1[0].strip().split(\" \")[-1]\n",
    "\n",
    "        if player is not None:\n",
    "            player = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", player)\n",
    "\n",
    "        s2 = \"\".join(s1[1:]).split(\":\")\n",
    "        if len(s2) >= 2:\n",
    "            score = int(s2[1].split(\"points\")[0].replace(\",\", \"\"))\n",
    "        else:\n",
    "            print(\"s2 error\", line)\n",
    "            return\n",
    "    else:\n",
    "        print(\"s1 error\", line)\n",
    "        return\n",
    "    return (player, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "image = cv2.imread(\"resources/ps11w4-winterstorms_plague-e99769/SCORE_INPUT/d298761e-a93a-415c-8588-d0011422af1c.png\")\n",
    "read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/src/resources/polytopia-helper-testing/SCORE_INPUT/9be6bc84-6b45-40a3-a3eb-062b65717336.png\"\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/src/Screenshot_20220208-192331.jpg\"\n",
    "image = cv2.imread(path)\n",
    "# score_image = crop(image)\n",
    "read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.image_to_string(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"header.png\", header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for path in [\n",
    "\t\"/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/MAP_INPUT/df3e5aa2-8f13-4a3c-9908-c8ec98d149d6.png\", \n",
    "\t\"/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/MAP_INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png\", \n",
    "\t\"/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/MAP_INPUT/0ec21a58-acd4-4d8a-a2bc-d047547d7f5b.png\"]:\n",
    "\timage = cv2.imread(path)\n",
    "\tcrop = image[:int(image.shape[0] / 6), :]\n",
    "\tgrayImage = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "\t# blur_kernel = 2\n",
    "\t# blur = cv2.blur(grayImage, (blur_kernel, blur_kernel))\n",
    "\t(thresh, blackAndWhiteImage) = cv2.threshold(grayImage, 100, 255, cv2.THRESH_BINARY)\n",
    "\tselected_image = blackAndWhiteImage\n",
    "\t# map_text = pytesseract.image_to_string(selected_image, config='--oem 3 --psm 6').split(\"\\n\")\n",
    "\t\n",
    "\tcontours, hierarchy = cv2.findContours(selected_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\trows = {}\n",
    "\trow_mins = {}\n",
    "\trow_maxes = {}\n",
    "\n",
    "\tfor c in contours:\n",
    "\t\tconvex_hull = cv2.convexHull(c, returnPoints=True)\n",
    "\t\t(y,x,h,w) = cv2.boundingRect(c)\n",
    "\t\tif w > 10 and h > 10:\n",
    "\t\t\tfound_row = False\n",
    "\t\t\tfor i in rows.keys():\n",
    "\t\t\t\tif found_row == False:\n",
    "\t\t\t\t\trow_min_i = row_mins[i]\n",
    "\t\t\t\t\trow_max_i = row_maxes[i]\n",
    "\t\t\t\t\tif x >= row_min_i and x + w <= row_max_i:\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\t\t\t\t\telif x >= row_min_i and x <= row_max_i and x + w >= row_max_i:\n",
    "\t\t\t\t\t\trow_max_i = x + w\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\t\t\t\t\telif x <= row_min_i and x + w >= row_min_i and x + w <= row_max_i:\n",
    "\t\t\t\t\t\trow_min_i = x\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\t\t\t\t\telif x <= row_min_i and x + w >= row_max_i:\n",
    "\t\t\t\t\t\trow_min_i = x\n",
    "\t\t\t\t\t\trow_max_i = x + w\n",
    "\t\t\t\t\t\tfound_row = True\n",
    "\t\t\t\t\t\trows[i] = rows[i] + [c]\n",
    "\n",
    "\t\t\t# cv2.rectangle(selected_image, (y,x), (y+h, x+w), (255, 0, 0), 2)\n",
    "\t\t\t# cv2.drawContours(selected_image, [convex_hull], 0, (255, 255, 255), 3)\n",
    "\t\t\n",
    "\t\t\tif not found_row:\n",
    "\t\t\t\tnew_i = len(rows.keys())\n",
    "\t\t\t\trows[new_i] = [c]\n",
    "\t\t\t\trow_mins[new_i] = x\n",
    "\t\t\t\trow_maxes[new_i] = x + w\n",
    "\t\n",
    "\tdelta = 15\n",
    "\tfound_turn = False\n",
    "\tfor i in rows.keys():\n",
    "\t\t# print(i, row_mins[i], row_maxes[i])\n",
    "\t\trow_min_i = max(row_mins[i] - delta, 0)\n",
    "\t\trow_max_i = min(row_maxes[i] + delta, selected_image.shape[0])\n",
    "\t\trow_image = selected_image[row_min_i:row_max_i]\n",
    "\t\tcv2.imwrite(\"binary_%d.png\" % i, row_image)\n",
    "\t\trow_text = pytesseract.image_to_string(row_image, config='--psm 6')\n",
    "\t\tcleared_row_text = row_text.replace(\"\\n\", \"\").replace(\"\\x0c\", \"\").split(\" \")\n",
    "\t\tif len(row_text) > 2 and row_text[2].isnumeric():\n",
    "\t\t\tturn = row_text[2]\n",
    "\t\t\tprint(turn, found_turn, path)\n",
    "\t\t\tfound_turn = True\n",
    "\tif not found_turn:\n",
    "\t\tprint(\"not found\", len(rows.keys()), path)\n",
    "\t\t# cv2.imwrite(\"gray.png\", grayImage)\n",
    "\t\t# cv2.imwrite(\"binary.png\", blackAndWhiteImage)\n",
    "\t\n",
    "\tif False: # and len(map_text) <= 1 or len(map_text[1].split(\" \")) <= 2 or map_text[1].split(\" \")[2] != \"11\":\n",
    "\t\tfor i in rows.keys():\n",
    "\t\t\t# print(i, row_mins[i], row_maxes[i])\n",
    "\t\t\trow_min_i = max(row_mins[i] - delta, 0)\n",
    "\t\t\trow_max_i = min(row_maxes[i] + delta, selected_image.shape[0])\n",
    "\t\t\trow_image = selected_image[row_min_i:row_max_i]\n",
    "\t\t\tcv2.imwrite(\"binary_%d.png\" % i, row_image)\n",
    "\t\t\trow_text = pytesseract.image_to_string(row_image, config='--psm 6').split(\" \")\n",
    "\t\t\tif len(row_text) > 2 and row_text[2].isnumeric():\n",
    "\t\t\t\tprint(row_text[2])\n",
    "\t\t# print(row_mins, row_maxes)\n",
    "\t\tcv2.imwrite(\"gray.png\", grayImage)\n",
    "\t\tcv2.imwrite(\"blur.png\", blur)\n",
    "\t\tcv2.imwrite(\"binary.png\", blackAndWhiteImage)\n",
    "\t\tprint(path)\n",
    "\t\tprint(map_text)\n",
    "\t\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"gray.png\", grayImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"binary.png\", blackAndWhiteImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_patching.map_patching_utils import patch_partial_maps\n",
    "\n",
    "# files = [\"3c3581aa-48fe-479a-9f82-8916cdcf2704\", \"1843f954-6e67-4aee-a493-f63f1043785c\"]\n",
    "# files = ['13bd77f1-9b3b-455e-b24f-43b0b0e726e2', '1d5c103a-3ce3-42d7-b16e-308b045e75b6', '6ad460f2-4673-4ed6-901e-4c1e0bf5cf69', '91dfdfdf-f7c0-4175-aab0-161b6da704b4']\n",
    "files = [\"22c03726-5e39-46aa-ad7b-fb247aa5c9d7\"]\n",
    "# channel_name = 'polytopia-helper-testing'\n",
    "channel_name = \"eli-jl-host-game-14\"\n",
    "await patch_partial_maps(channel_name, files, \"196\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/eli-jl-host-game-14/THREE_COLOR_EDGES/22c03726-5e39-46aa-ad7b-fb247aa5c9d7.png'\n",
    "img = cv2.imread(path,0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5\n",
    "blur = cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "thresh = cv2.threshold(blur, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "cv2.imwrite('./original.png', img)\n",
    "cv2.imwrite('./blur.png', blur)\n",
    "cv2.imwrite('./removed_dots.png', thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domainFilter = cv2.edgePreservingFilter(img, flags=1, sigma_s=90, sigma_r=0.9)\n",
    "cv2.imwrite('./domain_filter.png', domainFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0, -1, -3, -1, 0],\n",
    "                   [-1, -3, 5, -3, -1],\n",
    "\t\t\t\t   [-3, 5, 12, 5, -3],\n",
    "\t\t\t\t   [-1, -3, 5, -3, -1],\n",
    "\t\t\t\t   [0, -1, -3, -1, 0]])\n",
    "\n",
    "image_sharp = cv2.filter2D(src=img, ddepth=3, kernel=kernel)\n",
    "cv2.imwrite('./sharp.png', image_sharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel = cv2.getGaussianKernel(5, 0.5) \n",
    "\n",
    "corr_img = cv2.matchTemplate(img, gaussian_kernel, cv2.TM_CCOEFF_NORMED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path,0)\n",
    "# gray = img.astype(np.uint8)\n",
    "# normed = ((img / np.sum(img)) * 255).astype(np.uint8)\n",
    "distance_map = cv2.distanceTransform(255 - img.astype(np.uint8), cv2.DIST_C, 3).astype(np.float32)\n",
    "cv2.imwrite('./distance.png', distance_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(distance_map), np.max(distance_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_map = cv2.GaussianBlur(distance_map, (51, 51), 0.5)\n",
    "cv2.imwrite('./blur_map.png', blur_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(blur_map), np.max(blur_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, threshold = cv2.threshold(blur_map, 1, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh.png', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_patching import map_patching_utils\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/IMG_6815.png'\n",
    "# path = '/Users/jean/Documents/Coding/Polytopia/src/resources/eli-jl-host-game-14/MAP_INPUT/22c03726-5e39-46aa-ad7b-fb247aa5c9d7.png'\n",
    "img = cv2.imread(path)\n",
    "edges = map_patching_utils.get_three_color_edges(img)\n",
    "cv2.imwrite('./edges.png', edges)\n",
    "blur = cv2.GaussianBlur(edges, (25, 25), 6)\n",
    "val, threshold = cv2.threshold(blur, 30, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh_1.png', threshold)\n",
    "distance_map = cv2.distanceTransform(255 - threshold.astype(np.uint8), cv2.DIST_C, 3).astype(np.float32)\n",
    "blur_map = cv2.GaussianBlur(distance_map, (51, 51), 0.2)\n",
    "val, threshold = cv2.threshold(blur_map, 60, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh_2.png', threshold)\n",
    "distance_map = cv2.distanceTransform(255 - threshold.astype(np.uint8), cv2.DIST_L2, 3).astype(np.float32)\n",
    "val, threshold = cv2.threshold(distance_map, 70, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh.png', threshold)\n",
    "cv2.imwrite('./distance_map_bis.png', distance_map)\n",
    "masked_thresh = threshold.astype(np.uint8)[50:-50, 50:-50]\n",
    "print(type(masked_thresh), masked_thresh.dtype, masked_thresh.shape)\n",
    "mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "print(type(mask), mask.dtype, mask.shape)\n",
    "masked = cv2.bitwise_and(img, img, mask=masked_thresh)\n",
    "cv2.imwrite('./masked.png', masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/new-channel/THREE_COLOR_EDGES/f86ac4c3-5d42-4a8c-939d-e3c947035ae3.png'\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png'\n",
    "files = ['f86ac4c3-5d42-4a8c-939d-e3c947035ae3']\n",
    "files = ['1c3f544e-dc6c-4aff-b6cd-ac5408439269']\n",
    "\n",
    "channel_name = 'new-channel'\n",
    "channel_name = 'ps11w4-winterstorms_plague-e99769'\n",
    "from map_patching import map_patching_utils\n",
    "await map_patching_utils.patch_partial_maps(channel_name, files, 400, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from map_patching import map_patching_utils\n",
    "files = ['f86ac4c3-5d42-4a8c-939d-e3c947035ae3']\n",
    "processed_map, vertices_i, is_vertical_i = await map_patching_utils.process_raw_map(\n",
    "\tfiles[0], 1, 'new-channel', map_size=400, \n",
    "\tdatabase_client=None, message=None, kernel_size=5, sigma=5)\n",
    "cv2.imwrite('./processed_map.png', processed_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/Screenshot_20220125_143137_air.com.midjiwan.polytopia.jpg'\n",
    "img = cv2.imread(path)\n",
    "\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "light = (0, 0, 0)\n",
    "dark = (10, 10, 10)\n",
    "mask = cv2.inRange(hsv, light, dark)\n",
    "cv2.imwrite('./mask.png', mask)\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imwrite('./colour.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from common import image_utils\n",
    "def remove_clouds(img, ksize=7, sigma=15):    \n",
    "    # new_dim = (int(img.shape[1] * 0.5), int(img.shape[0] * 0.5))\n",
    "    # img = cv2.resize(img, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    # print(img.shape)\n",
    "\n",
    "    template = image_utils.get_cloud_template()\n",
    "    # new_dim = (int(template.shape[1] * 0.5), int(template.shape[0] * 0.5))\n",
    "    # template = cv2.resize(template, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    hh, ww = template.shape[:2]\n",
    "    print(template.shape)\n",
    "\n",
    "    pawn = template[:, :, 0:3]\n",
    "    alpha_template = template[:, :, 3]\n",
    "    alpha = cv2.merge([alpha_template, alpha_template, alpha_template])\n",
    "\n",
    "    result_set = []\n",
    "\n",
    "    for scale in range(90, 110, 2):# np.linspace(0.4, 2, 50)[::-1]:\n",
    "        scale = scale / 100.0\n",
    "        new_dim = (int(img.shape[1] * scale), int(img.shape[0] * scale))\n",
    "        resized = cv2.resize(img, new_dim, interpolation=cv2.INTER_AREA)\n",
    "        if resized.shape[0] < template.shape[0] or resized.shape[1] < template.shape[1]:\n",
    "            break\n",
    "\n",
    "        img_alpha = np.ones((resized.shape[0:2]))\n",
    "        \n",
    "        corr_img = cv2.matchTemplate(resized, pawn, cv2.TM_CCOEFF_NORMED, mask=alpha)\n",
    "        correlation_raw = (255 * corr_img).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        blur = cv2.GaussianBlur(correlation_raw, (ksize, ksize), sigmaX=sigma)\n",
    "        threshold = 100\n",
    "\n",
    "        # cv2.imwrite('./cloud/blur_%.2f.png' % scale, blur)\n",
    "        \n",
    "        maximum = np.max(blur)\n",
    "        \n",
    "        result = img.copy()\n",
    "        max_val = np.max(blur)\n",
    "        rad = int(math.sqrt(hh * hh + ww * ww) / 4)\n",
    "\n",
    "        count = 0\n",
    "        \n",
    "        while max_val > threshold:\n",
    "\n",
    "            # find max value of correlation image\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(blur)\n",
    "\n",
    "            if max_val > threshold:\n",
    "                # draw match on copy of input\n",
    "                # cv2.rectangle(result, max_loc, (max_loc[0]+ww, max_loc[1]+hh), (0, 0, 255), 2)\n",
    "                img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] = \\\n",
    "                    img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] - alpha_template / 255.0\n",
    "\n",
    "                # write black circle at max_loc in corr_img\n",
    "                cv2.circle(blur, (max_loc), radius=rad, color=0, thickness=cv2.FILLED)\n",
    "                count += 1\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        img_alpha_c = img_alpha.clip(0, 1).astype(np.uint8)\n",
    "        mask = cv2.merge([img_alpha_c, img_alpha_c, img_alpha_c]).astype(np.uint8)\n",
    "        # result = cv2.multiply(resized, mask)\n",
    "        # cv2.imwrite('./cloud/alpha_%.2f.png' % scale, result)\n",
    "        # cv2.imwrite('./cloud/blur_blocked_%.2f.png' % scale, blur)\n",
    "        alpha_area = np.sum(img_alpha_c == 0) / (img_alpha_c.shape[0] * img_alpha_c.shape[1])\n",
    "        # print(\"scale %.2f: %d, %.2f, %d, %.4f\" % (scale, maximum, maximum / (scale), count, alpha_area))\n",
    "        result_set.append([scale, maximum, maximum / scale, count, alpha_area, mask])\n",
    "    selected_scaling = sorted(result_set, key=lambda x: -x[2])[0]\n",
    "    print(selected_scaling[:5])\n",
    "    resized_original = cv2.resize(selected_scaling[5], (img.shape[1], img.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    return resized_original\n",
    "\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png'\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/2a0de14a-c3dc-4d6f-b1ee-b9a42be4725d.png'\n",
    "files = ['1c3f544e-dc6c-4aff-b6cd-ac5408439269']\n",
    "channel_name = 'ps11w4-winterstorms_plague-e99769'\n",
    "\n",
    "img = cv2.imread(path)\n",
    "without_cloud = remove_clouds(img)\n",
    "print(img.shape, without_cloud.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob(scale, blur):\n",
    "\t# img_gray = cv2.imread('./cloud/blur_%.2f.png' % scale, cv2.IMREAD_GRAYSCALE)\n",
    "\t# keypoints = detector.detect(img_gray)\n",
    "\t# print(keypoints[0])\n",
    "\t# im_with_keypoints = cv2.drawKeypoints(img_gray, keypoints, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\t# blobs('./cloud/blur_%.2f.png' % scale)\n",
    "\t# cv2.imwrite('./cloud/blobs_%.2f.png' % scale, im_with_keypoints)\n",
    "\tthresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "\tcv2.imwrite('./cloud/thresh_%.2f.png' % scale, thresh)\n",
    "\toutput = cv2.connectedComponentsWithStats(thresh, 4, cv2.CV_32S)\n",
    "\t(numLabels, labels, stats, centroids) = output\n",
    "\tsum_mask = np.zeros_like(thresh)\n",
    "\n",
    "\tfor i in range(0, numLabels):\n",
    "\t\tmask = (labels == i).astype(\"uint8\") * 255\n",
    "\t\tif np.sum(mask) > 2 and np.sum(mask) < 1000:\n",
    "\t\t\tsum_mask = (sum_mask + mask).clip(0, 255)\n",
    "\t\t\n",
    "\tcv2.imwrite('./cloud/blobs_%.2f.png' % (scale), sum_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "# Read the main image\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png'\n",
    "img_rgb = cv2.imread(path)\n",
    "  \n",
    "# Convert to grayscale\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Read the template\n",
    "template = cv2.imread('/Users/jean/Documents/Coding/Polytopia/src/templates/cloud_template.png',0)\n",
    "  \n",
    "# Store width and height of template in w and h\n",
    "w, h = template.shape[::-1]\n",
    "found = None\n",
    " \n",
    "for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    " \n",
    "    # resize the image according to the scale, and keep track\n",
    "    # of the ratio of the resizing\n",
    "    new_dim = (int(img_gray.shape[1] * scale), int(image.shape[0] * scale))\n",
    "    resized = cv2.resize(img_gray, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    r = img_gray.shape[1] / float(resized.shape[1])\n",
    "  \n",
    "    # detect edges in the resized, grayscale image and apply template\n",
    "    # matching to find the template in the image \n",
    "    edged = cv2.Canny(resized, 50, 200) \n",
    "    result = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF)\n",
    "    (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)\n",
    "    # if we have found a new maximum correlation value, then update\n",
    "    # the found variable if found is None or maxVal > found[0]:\n",
    "    if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            break\n",
    "    found = (maxVal, maxLoc, r)\n",
    "  \n",
    "# unpack the found variable and compute the (x, y) coordinates\n",
    "# of the bounding box based on the resized ratio\n",
    "(_, maxLoc, r) = found\n",
    "(startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "(endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    " \n",
    "# draw a bounding box around the detected result and display the image\n",
    "cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np;  \n",
    "\n",
    "def blobs(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  \n",
    "\n",
    "    # Set up the detector with default parameters.  \n",
    "    detector = cv2.SimpleBlobDetector()  \n",
    "    \n",
    "    # Detecting blobs.  cv2.cvtColor(img, cv2.COLOR_)\n",
    "    keypoints = detector.detect(img)\n",
    "    # Draw detected blobs as red circles.  \n",
    "    # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob  \n",
    "    # im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return # im_with_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "from score_recognition import score_recognition_utils\n",
    "\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/tests/resources/score_recognition/image_3.png\"\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/Screenshot_20220210_233213_air.com.midjiwan.polytopia.jpg\"\n",
    "image = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = score_recognition_utils.read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "import numpy as np\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "light = (256, 256, 256)\n",
    "dark = (100, 0, 100)\n",
    "#dark = (120, 0, 50)\n",
    "#light = (230, 40, 150)\n",
    "\n",
    "# light = (255, 255, 255)\n",
    "# dark = (150, 150, 150)\n",
    "light = (200, 256, 256)\n",
    "dark = (0, 210, 200)\n",
    "\n",
    "mask = cv2.inRange(hsv, dark, light)\n",
    "print(np.min(mask), np.max(mask))\n",
    "cv2.imwrite('./mask.png', mask)\n",
    "result = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imwrite('./colour.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert = cv2.invert(image)\n",
    "img_not = cv2.bitwise_not(image)\n",
    "cv2.imwrite('./inverted.png', img_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = score_recognition_utils.get_scores(img_not, only_you=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def clear_noise(image):\n",
    "    # Loop through every pixel in the box and color the\n",
    "    # pixel accordingly\n",
    "    value  = (np.array(0.3 * image[:, :, 2] + 0.59 * image[:, :, 1] + 0.11 * image[:, :, 0])).astype(np.uint8)\n",
    "    # new_image = [[ii(pixel) for pixel in row] for row in image]\n",
    "    return cv2.threshold(value, 170, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "cleared = clear_noise(image)\n",
    "cv2.imwrite('./invert/new_img.png' , cleared)\n",
    "\n",
    "image_reading = score_recognition_utils.read(cleared)\n",
    "image_text = image_reading.split('\\n')\n",
    "scores = [score_recognition_utils.read_line(t) for t in image_text if \"score\" in t]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(image, only_you=False):\n",
    "    logger.debug(\"read image scores\")\n",
    "    image_reading = read(image)\n",
    "    logger.debug(\"image reading: %s\" % image_reading)\n",
    "    image_text = image_reading.replace(\"¢\", \"c\").split('\\n')\n",
    "    print(\"image text\", only_you, image_text)\n",
    "    scores = [read_line(t) for t in image_text if \"score\" in t and (not only_you or \"Ruled by you\" in t)]\n",
    "    logger.debug(scores)\n",
    "    print(\"scores\", only_you, scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel intensity = 0.30R + 0.59G + 0.11B\n",
    "img_y = len(image)\n",
    "img_x = len(image[0])\n",
    "\n",
    "def ii(xx, yy):\n",
    "    if yy >= img_y or xx >= img_x:\n",
    "        # print \"pixel out of bounds (\"+str(y)+\",\"+str(x)+\")\"\n",
    "        return 0\n",
    "    pixel = image[yy][xx]\n",
    "    return 0.30 * pixel[2] + 0.59 * pixel[1] + 0.11 * pixel[0]\n",
    "\n",
    "inverted = image.copy()\n",
    "new_image = inverted.copy()\n",
    "new_image.fill(255)\n",
    "width = inverted.shape[1]\n",
    "height = inverted.shape[0]\n",
    "\n",
    "if False:\n",
    "\tfg = 255\n",
    "\tbg = 0\n",
    "else:\n",
    "\tfg = 0\n",
    "\tbg = 255\n",
    "\n",
    "for fg_int in range(0, 251, 10):\n",
    "\t# Loop through every pixel in the box and color the\n",
    "\t# pixel accordingly\n",
    "\tfor x in range(width):\n",
    "\t\tfor y in range(height):\n",
    "\t\t\tif ii(x, y) > fg_int:\n",
    "\t\t\t\tnew_image[y][x] = bg\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_image[y][x] = fg\n",
    "\tcv2.imwrite('./invert/new_img_%d_%d.png' % (fg_int, fg), new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_noise(orig_img, border_width=50, low_threshold=200, high_threshold=250, blur_kernel=2, min_size=15):\n",
    "    global img, img_y, img_x, contours\n",
    "\n",
    "    # Add a border to the image for processing sake\n",
    "    img = cv2.copyMakeBorder(orig_img, border_width, border_width, border_width, border_width, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    # Calculate the width and height of the image\n",
    "    img_y = len(img)\n",
    "    img_x = len(img[0])\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"Image is \" + str(len(img)) + \"x\" + str(len(img[0])))\n",
    "\n",
    "    edges = image_processing_utils.get_three_color_edges(img, low_thresh=low_threshold, high_thresh=high_threshold)\n",
    "\n",
    "    # Find the contours\n",
    "    contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    hierarchy = hierarchy[0]\n",
    "\n",
    "    processed = edges.copy() if DEBUG else None\n",
    "    rejected = edges.copy() if DEBUG else None\n",
    "\n",
    "    keepers = select_contours(hierarchy, min_size, processed, rejected)\n",
    "\n",
    "    new_image = invert_bg_fg_if_needed(edges, keepers)\n",
    "\n",
    "    # blur a bit to improve ocr accuracy\n",
    "    if blur_kernel is not None:\n",
    "        new_image = cv2.blur(new_image, (blur_kernel, blur_kernel))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def select_contours(hierarchy, min_size, processed=None, rejected=None):\n",
    "    # These are the boxes that we are determining\n",
    "    keepers = []\n",
    "\n",
    "    # For each contour, find the bounding rectangle and decide\n",
    "    # if it's one we care about\n",
    "    for index_, contour_ in enumerate(contours):\n",
    "        if DEBUG:\n",
    "            print(\"Processing #%d\" % index_)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour_)\n",
    "\n",
    "        # Check the contour and it's bounding box\n",
    "        if keep(contour_, min_size) and include_box(index_, hierarchy, contour_, min_size):\n",
    "            # It's a winner!\n",
    "            keepers.append([contour_, [x, y, w, h]])\n",
    "            if DEBUG and processed is not None:\n",
    "                cv2.rectangle(processed, (x, y), (x + w, y + h), (100, 100, 100), 1)\n",
    "                cv2.putText(processed, str(index_), (x, y - 5), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255))\n",
    "        else:\n",
    "            if DEBUG and rejected is not None:\n",
    "                cv2.rectangle(rejected, (x, y), (x + w, y + h), (100, 100, 100), 1)\n",
    "                cv2.putText(rejected, str(index_), (x, y - 5), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255))\n",
    "    return keepers\n",
    "\n",
    "\n",
    "def invert_bg_fg_if_needed(edges, keepers):\n",
    "    # Make a white copy of our image\n",
    "    new_image = edges.copy()\n",
    "    new_image.fill(255)\n",
    "\n",
    "    # For each box, find the foreground and background intensities\n",
    "    for index_, (contour_, box) in enumerate(keepers):\n",
    "\n",
    "        # Find the average intensity of the edge pixels to\n",
    "        # determine the foreground intensity\n",
    "        fg_int = sum(ii(p[0][0], p[0][1]) for p in contour_) / len(contour_)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"FG Intensity for #%d = %d\" % (index_, fg_int))\n",
    "\n",
    "        # Find the intensity of three pixels going around the\n",
    "        # outside of each corner of the bounding box to determine\n",
    "        # the background intensity\n",
    "        x_, y_, width, height = box\n",
    "        bg_int = get_corner_background_intensity(x_, y_, width, height)\n",
    "\n",
    "        # Find the median of the background\n",
    "        # pixels determined above\n",
    "        bg_int = np.median(bg_int)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"BG Intensity for #%d = %s\" % (index_, repr(bg_int)))\n",
    "\n",
    "        # Determine if the box should be inverted\n",
    "        if fg_int >= bg_int:\n",
    "            fg = 255\n",
    "            bg = 0\n",
    "        else:\n",
    "            fg = 0\n",
    "            bg = 255\n",
    "\n",
    "        # Loop through every pixel in the box and color the\n",
    "        # pixel accordingly\n",
    "        for x in range(x_, x_ + width):\n",
    "            for y in range(y_, y_ + height):\n",
    "                if y >= img_y or x >= img_x:\n",
    "                    if DEBUG:\n",
    "                        print(\"pixel out of bounds (%d,%d)\" % (y, x))\n",
    "                    continue\n",
    "                if ii(x, y) > fg_int:\n",
    "                    new_image[y][x] = bg\n",
    "                else:\n",
    "                    new_image[y][x] = fg\n",
    "    return new_image\n",
    "\t\n",
    "DEBUG = 1\n",
    "\n",
    "# Determine pixel intensity\n",
    "# Apparently human eyes register colors differently.\n",
    "# TVs use this formula to determine\n",
    "# pixel intensity = 0.30R + 0.59G + 0.11B\n",
    "def ii(xx, yy):\n",
    "    global img, img_y, img_x\n",
    "    if yy >= img_y or xx >= img_x:\n",
    "        # print \"pixel out of bounds (\"+str(y)+\",\"+str(x)+\")\"\n",
    "        return 0\n",
    "    pixel = img[yy][xx]\n",
    "    return 0.30 * pixel[2] + 0.59 * pixel[1] + 0.11 * pixel[0]\n",
    "\n",
    "\n",
    "# A quick test to check whether the contour is\n",
    "# a connected shape\n",
    "def connected(contour):\n",
    "    first = contour[0][0]\n",
    "    last = contour[len(contour) - 1][0]\n",
    "    return abs(first[0] - last[0]) <= 1 and abs(first[1] - last[1]) <= 1\n",
    "\n",
    "\n",
    "# Helper function to return a given contour\n",
    "def c(index):\n",
    "    global contours\n",
    "    return contours[index]\n",
    "\n",
    "\n",
    "# Count the number of real children\n",
    "def count_children(index, h_, contour, min_size):\n",
    "    # No children\n",
    "    if h_[index][2] < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        # If the first child is a contour we care about\n",
    "        # then count it, otherwise don't\n",
    "        if keep(c(h_[index][2]), min_size):\n",
    "            count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "\n",
    "            # Also count all of the child's siblings and their children\n",
    "        count += count_siblings(h_[index][2], h_, contour, min_size, True)\n",
    "        return count\n",
    "\n",
    "\n",
    "# Quick check to test if the contour is a child\n",
    "def is_child(index, h_, min_size):\n",
    "    return get_parent(index, h_, min_size) > 0\n",
    "\n",
    "\n",
    "# Get the first parent of the contour that we care about\n",
    "def get_parent(index, h_, min_size):\n",
    "    parent = h_[index][3]\n",
    "    while not keep(c(parent), min_size) and parent > 0:\n",
    "        parent = h_[parent][3]\n",
    "\n",
    "    return parent\n",
    "\n",
    "\n",
    "# Count the number of relevant siblings of a contour\n",
    "def count_siblings(index, h_, contour, min_size, inc_children=False):\n",
    "    # Include the children if necessary\n",
    "    if inc_children:\n",
    "        count = count_children(index, h_, contour, min_size)\n",
    "    else:\n",
    "        count = 0\n",
    "\n",
    "    # Look ahead\n",
    "    p_ = h_[index][0]\n",
    "    while p_ > 0:\n",
    "        if keep(c(p_), min_size):\n",
    "            count += 1\n",
    "        if inc_children:\n",
    "            count += count_children(p_, h_, contour, min_size)\n",
    "        p_ = h_[p_][0]\n",
    "\n",
    "    # Look behind\n",
    "    n = h_[index][1]\n",
    "    while n > 0:\n",
    "        if keep(c(n), min_size):\n",
    "            count += 1\n",
    "        if inc_children:\n",
    "            count += count_children(n, h_, contour, min_size)\n",
    "        n = h_[n][1]\n",
    "    return count\n",
    "\n",
    "\n",
    "# Whether we care about this contour\n",
    "def keep(contour, min_size):\n",
    "    global img_y, img_x\n",
    "    return keep_box(contour, img_x, img_y, min_size) and connected(contour)\n",
    "\n",
    "\n",
    "# Whether we should keep the containing box of this\n",
    "# contour based on it's shape\n",
    "def keep_box(contour, img_x, img_y, min_size):\n",
    "    xx, yy, w_, h_ = cv2.boundingRect(contour)\n",
    "\n",
    "    # width and height need to be floats\n",
    "    w_ *= 1.0\n",
    "    h_ *= 1.0\n",
    "\n",
    "    # Test it's shape - if it's too oblong or tall it's\n",
    "    # probably not a real character\n",
    "    if w_ / h_ < 0.1 or w_ / h_ > 10:\n",
    "        if DEBUG:\n",
    "            print(\"\\t Rejected because of shape: (\" + str(xx) + \",\" + str(yy) + \",\" +\n",
    "                  str(w_) + \",\" + str(h_) + \")\" + str(w_ / h_))\n",
    "        return False\n",
    "\n",
    "    # check size of the box\n",
    "    if ((w_ * h_) > ((img_x * img_y) / 5)) or ((w_ * h_) < min_size):\n",
    "        if DEBUG:\n",
    "            print(\"\\t Rejected because of size\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def include_box(index, h_, contour, min_size):\n",
    "    if DEBUG:\n",
    "        print(str(index) + \":\")\n",
    "        if is_child(index, h_, min_size):\n",
    "            print(\"\\tIs a child\")\n",
    "            print(\"\\tparent \" + str(get_parent(index, h_, min_size)) + \" has \" + str(\n",
    "                count_children(get_parent(index, h_, min_size), h_, contour, min_size)) + \" children\")\n",
    "            print(\"\\thas \" + str(count_children(index, h_, contour, min_size)) + \" children\")\n",
    "\n",
    "    if is_child(index, h_, min_size) and count_children(get_parent(index, h_, min_size), h_, contour, min_size) <= 2:\n",
    "        if DEBUG:\n",
    "            print(\"\\t skipping: is an interior to a letter\")\n",
    "        return False\n",
    "\n",
    "    if count_children(index, h_, contour, min_size) > 2:\n",
    "        if DEBUG:\n",
    "            print(\"\\t skipping, is a container of letters\")\n",
    "        return False\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"\\t keeping\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_corner_background_intensity(x_, y_, width, height):\n",
    "    return [\n",
    "        # bottom left corner 3 pixels\n",
    "        ii(x_ - 1, y_ - 1),\n",
    "        ii(x_ - 1, y_),\n",
    "        ii(x_, y_ - 1),\n",
    "\n",
    "        # bottom right corner 3 pixels\n",
    "        ii(x_ + width + 1, y_ - 1),\n",
    "        ii(x_ + width, y_ - 1),\n",
    "        ii(x_ + width + 1, y_),\n",
    "\n",
    "        # top left corner 3 pixels\n",
    "        ii(x_ - 1, y_ + height + 1),\n",
    "        ii(x_ - 1, y_ + height),\n",
    "        ii(x_, y_ + height + 1),\n",
    "\n",
    "        # top right corner 3 pixels\n",
    "        ii(x_ + width + 1, y_ + height + 1),\n",
    "        ii(x_ + width, y_ + height + 1),\n",
    "        ii(x_ + width + 1, y_ + height)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [10, 20, 30, 50, 60, 70, 80, 90, 100]\n",
    "index = 3\n",
    "array.pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
