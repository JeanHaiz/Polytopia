{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from map_patching import map_patching_utils\n",
    "from score_recognition import score_recognition_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = score_recognition_utils.read_scores('../attachments/20211208_214922_918242881284751360.png')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"image30.jpg\", \"image31.jpg\"]\n",
    "patchwork = map_patching_utils.patch_partial_maps(files, \"example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"image41.jpg\", \"image40.jpg\"]\n",
    "patchwork = map_patching_utils.patch_partial_maps(files, \"winter&&storms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference_positions:\n",
    "\n",
    "top: (1121, 274)\n",
    "\n",
    "left: (105, 880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "root_path = \"/Users/jean/Documents/Coding/Polytopia/resources/\"\n",
    "image_path = root_path + \"bot_patch.png\"\n",
    "template_path = root_path + \"bot_patch_alpha.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch.png\")\n",
    "template = cv2.imread(\"/Users/jean/Documents/Coding/Polytopia/resources/bot_patch_alpha.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('/Users/jean/Documents/Coding/Polytopia/resources/detected.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from score_recognition.score_recognition_utils import *\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/src/resources/polytopia-helper-testing/SCORE_INPUT/9be6bc84-6b45-40a3-a3eb-062b65717336.png\"\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/src/Screenshot_20220208-192331.jpg\"\n",
    "image = cv2.imread(path)\n",
    "# score_image = crop(image)\n",
    "read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_patching_utils background\n",
      "map size 196\n",
      "orientation True 1.5805739514348787\n",
      "map_patching_utils 3c3581aa-48fe-479a-9f82-8916cdcf2704\n",
      "Image valid 2280\n",
      "orientation True 0.9601769911504425\n",
      "map_patching_utils 1843f954-6e67-4aee-a493-f63f1043785c\n",
      "Image valid 2280\n",
      "orientation True 0.9442993907745866\n",
      "map_patching_utils 91dfdfdf-f7c0-4175-aab0-161b6da704b4\n",
      "Image valid 2280\n",
      "orientation True 0.8858102434928632\n",
      "scale 92.21428571428571\n",
      "img shape (1396, 2047, 3)\n",
      "sizes: (1396, 2047, 3) (1396, 2047, 3)\n",
      "scale 92.21428571428571\n",
      "img shape (2327, 1138, 3)\n",
      "sizes: (2327, 1138, 3) (2327, 1138, 3)\n",
      "scale 92.21428571428571\n",
      "img shape (2317, 1118, 3)\n",
      "sizes: (2317, 1118, 3) (2317, 1118, 3)\n",
      "scale 92.21428571428571\n",
      "img shape (2280, 1080, 3)\n",
      "sizes: (2280, 1080, 3) (2280, 1080, 3)\n",
      "(1396, 2047, 3) (1396, 2047, 3)\n",
      "scaled_padding [509   0]\n",
      "size (1396, 2047)\n",
      "bit size (1396, 2047, 3)\n",
      "(2327, 1138, 3) (2327, 1138, 3)\n",
      "scaled_padding [  0 487]\n",
      "size (2327, 1138)\n",
      "bit size (2327, 1138, 3)\n",
      "(2317, 1118, 3) (2317, 1118, 3)\n",
      "scaled_padding [  0 527]\n",
      "size (2317, 1118)\n",
      "bit size (2317, 1118, 3)\n",
      "(2280, 1080, 3) (2280, 1080, 3)\n",
      "scaled_padding [135 979]\n",
      "size (2280, 1080)\n",
      "bit size (2280, 1080, 3)\n",
      "/Users/jean/Documents/Coding/Polytopia/src/resources/polytopia-helper-testing/MAP_PATCHING_OUTPUT/map_patching_debug.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['POLYTOPIA_DEBUG'] = \"0\"\n",
    "from map_patching.map_patching_utils import patch_partial_maps\n",
    "\n",
    "files = [\"3c3581aa-48fe-479a-9f82-8916cdcf2704\", \"1843f954-6e67-4aee-a493-f63f1043785c\", \"91dfdfdf-f7c0-4175-aab0-161b6da704b4\"]\n",
    "# files = ['13bd77f1-9b3b-455e-b24f-43b0b0e726e2', '1d5c103a-3ce3-42d7-b16e-308b045e75b6', '6ad460f2-4673-4ed6-901e-4c1e0bf5cf69', '91dfdfdf-f7c0-4175-aab0-161b6da704b4']\n",
    "# files = [\"22c03726-5e39-46aa-ad7b-fb247aa5c9d7\"]\n",
    "# files = ['IMG_1123', 'IMG_1124']\n",
    "# files = ['IMG_1308', 'IMG_8255']\n",
    "channel_name = 'polytopia-helper-testing'\n",
    "# channel_name = \"eli-jl-host-game-14\"\n",
    "# channel_name = \"win-away-vs--reef-of-prophecy-game4\"\n",
    "# channel_name = 'map-of-faith-game5'\n",
    "patch_path, filename = await patch_partial_maps(channel_name, files, \"196\")\n",
    "print(patch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_patching.map_patching_utils import split_in_rows\n",
    "from common import image_utils\n",
    "from common.image_utils import ImageOp\n",
    "DEBUG = 1\n",
    "\n",
    "def prepare_turn_image(image, low_thresh):\n",
    "    crop = image[:int(image.shape[0] / 4), :]\n",
    "    grayImage = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    (_, thresh) = cv2.threshold(grayImage, low_thresh, 255, cv2.THRESH_BINARY)\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_LIST,\n",
    "                    cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    for cnt in cnts:\n",
    "        if cv2.contourArea(cnt) < 15:\n",
    "            cv2.fillPoly(thresh, [cnt], color=(0,0,0))\n",
    "    return thresh\n",
    "\n",
    "def get_turn(image, low_thresh=130, channel_name=None):\n",
    "    selected_image = prepare_turn_image(image, low_thresh)\n",
    "    cv2.imwrite('./bin.png', 255 - selected_image)\n",
    "    # map_text = pytesseract.image_to_string(selected_image, config='--oem 3 --psm 6').split(\"\\n\")\n",
    "\n",
    "    contours, _ = cv2.findContours(selected_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    rows, row_mins, row_maxes = split_in_rows(contours)\n",
    "\n",
    "    delta = 15\n",
    "    turn = None\n",
    "    for i in rows.keys():\n",
    "        row_min_i = max(row_mins[i] - delta, 0)\n",
    "        row_max_i = min(row_maxes[i] + delta, selected_image.shape[0])\n",
    "        row_image = selected_image[row_min_i:row_max_i]\n",
    "        if DEBUG and channel_name is not None:\n",
    "            image_utils.save_image(row_image, channel_name, \"binary_%d\" % i, ImageOp.TURN_PIECES)\n",
    "        row_text = pytesseract.image_to_string(255 - row_image, config='--psm 6 -c load_system_dawg=0 load_freq_dawg=0 load_punc_dawg=0')\n",
    "        print(row_text)\n",
    "        cleared_row_text = row_text.replace(\"\\n\", \"\").replace(\"\\x0c\", \"\")\n",
    "        cleared_row_text = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", cleared_row_text)\n",
    "        if 'Scores' not in cleared_row_text and 'Stars' not in cleared_row_text:\n",
    "            cleared_row_numbers = re.sub(r\"[^0-9 ]\", \"\", cleared_row_text).replace(\"  \", \" \").strip()\n",
    "            print(i, cleared_row_numbers)\n",
    "            cleared_row_text_split = cleared_row_numbers.split(\" \")\n",
    "            if len(cleared_row_text_split) > 2 and cleared_row_text_split[2].isnumeric():\n",
    "                turn = cleared_row_text_split[2]\n",
    "    if DEBUG:\n",
    "        if turn is None:\n",
    "            if low_thresh > 160:\n",
    "                print(\"turn not recognised\")\n",
    "            else:\n",
    "                return get_turn(image, low_thresh + 10)\n",
    "        else:\n",
    "            print(\"turn %s\" % turn)\n",
    "    return turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import discord\n",
    "import asyncio\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from common import image_utils\n",
    "from common.image_utils import ImageOp\n",
    "from common import image_processing_utils\n",
    "from database_interaction import database_client\n",
    "from map_patching import map_patching_utils\n",
    "os.environ['POLYTOPIA_DEBUG'] = \"1\"\n",
    "image = cv2.imread('/Users/jean/Documents/Coding/Polytopia/tests/resources/map_patching/image_8.png')\n",
    "turn = get_turn(image, channel_name=\"general\")\n",
    "print(turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_patching import map_patching_utils\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/IMG_6815.png'\n",
    "# path = '/Users/jean/Documents/Coding/Polytopia/src/resources/eli-jl-host-game-14/MAP_INPUT/22c03726-5e39-46aa-ad7b-fb247aa5c9d7.png'\n",
    "img = cv2.imread(path)\n",
    "edges = map_patching_utils.get_three_color_edges(img)\n",
    "cv2.imwrite('./edges.png', edges)\n",
    "blur = cv2.GaussianBlur(edges, (25, 25), 6)\n",
    "val, threshold = cv2.threshold(blur, 30, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh_1.png', threshold)\n",
    "distance_map = cv2.distanceTransform(255 - threshold.astype(np.uint8), cv2.DIST_C, 3).astype(np.float32)\n",
    "blur_map = cv2.GaussianBlur(distance_map, (51, 51), 0.2)\n",
    "val, threshold = cv2.threshold(blur_map, 60, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh_2.png', threshold)\n",
    "distance_map = cv2.distanceTransform(255 - threshold.astype(np.uint8), cv2.DIST_L2, 3).astype(np.float32)\n",
    "val, threshold = cv2.threshold(distance_map, 70, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('./thresh.png', threshold)\n",
    "cv2.imwrite('./distance_map_bis.png', distance_map)\n",
    "masked_thresh = threshold.astype(np.uint8)[50:-50, 50:-50]\n",
    "print(type(masked_thresh), masked_thresh.dtype, masked_thresh.shape)\n",
    "mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "print(type(mask), mask.dtype, mask.shape)\n",
    "masked = cv2.bitwise_and(img, img, mask=masked_thresh)\n",
    "cv2.imwrite('./masked.png', masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/new-channel/THREE_COLOR_EDGES/f86ac4c3-5d42-4a8c-939d-e3c947035ae3.png'\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png'\n",
    "files = ['f86ac4c3-5d42-4a8c-939d-e3c947035ae3']\n",
    "files = ['1c3f544e-dc6c-4aff-b6cd-ac5408439269']\n",
    "\n",
    "channel_name = 'new-channel'\n",
    "channel_name = 'ps11w4-winterstorms_plague-e99769'\n",
    "from map_patching import map_patching_utils\n",
    "await map_patching_utils.patch_partial_maps(channel_name, files, 400, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from map_patching import map_patching_utils\n",
    "files = ['f86ac4c3-5d42-4a8c-939d-e3c947035ae3']\n",
    "processed_map, vertices_i, is_vertical_i = await map_patching_utils.process_raw_map(\n",
    "    files[0], 1, 'new-channel', map_size=400, \n",
    "    database_client=None, message=None, kernel_size=5, sigma=5)\n",
    "cv2.imwrite('./processed_map.png', processed_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/Screenshot_20220125_143137_air.com.midjiwan.polytopia.jpg'\n",
    "img = cv2.imread(path)\n",
    "\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "light = (0, 0, 0)\n",
    "dark = (10, 10, 10)\n",
    "mask = cv2.inRange(hsv, light, dark)\n",
    "cv2.imwrite('./mask.png', mask)\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imwrite('./colour.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from common import image_utils\n",
    "def remove_clouds(img, ksize=7, sigma=15):\n",
    "    # new_dim = (int(img.shape[1] * 0.5), int(img.shape[0] * 0.5))\n",
    "    # img = cv2.resize(img, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    # print(img.shape)\n",
    "\n",
    "    template = image_utils.get_cloud_template()\n",
    "    # new_dim = (int(template.shape[1] * 0.5), int(template.shape[0] * 0.5))\n",
    "    # template = cv2.resize(template, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    hh, ww = template.shape[:2]\n",
    "    print(template.shape)\n",
    "\n",
    "    pawn = template[:, :, 0:3]\n",
    "    alpha_template = template[:, :, 3]\n",
    "    alpha = cv2.merge([alpha_template, alpha_template, alpha_template])\n",
    "\n",
    "    result_set = []\n",
    "\n",
    "    for scale in range(90, 110, 2):# np.linspace(0.4, 2, 50)[::-1]:\n",
    "        scale = scale / 100.0\n",
    "        new_dim = (int(img.shape[1] * scale), int(img.shape[0] * scale))\n",
    "        resized = cv2.resize(img, new_dim, interpolation=cv2.INTER_AREA)\n",
    "        if resized.shape[0] < template.shape[0] or resized.shape[1] < template.shape[1]:\n",
    "            break\n",
    "\n",
    "        img_alpha = np.ones((resized.shape[0:2]))\n",
    "        \n",
    "        corr_img = cv2.matchTemplate(resized, pawn, cv2.TM_CCOEFF_NORMED, mask=alpha)\n",
    "        correlation_raw = (255 * corr_img).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        blur = cv2.GaussianBlur(correlation_raw, (ksize, ksize), sigmaX=sigma)\n",
    "        threshold = 100\n",
    "\n",
    "        # cv2.imwrite('./cloud/blur_%.2f.png' % scale, blur)\n",
    "        \n",
    "        maximum = np.max(blur)\n",
    "        \n",
    "        result = img.copy()\n",
    "        max_val = np.max(blur)\n",
    "        rad = int(math.sqrt(hh * hh + ww * ww) / 4)\n",
    "\n",
    "        count = 0\n",
    "        \n",
    "        while max_val > threshold:\n",
    "\n",
    "            # find max value of correlation image\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(blur)\n",
    "\n",
    "            if max_val > threshold:\n",
    "                # draw match on copy of input\n",
    "                # cv2.rectangle(result, max_loc, (max_loc[0]+ww, max_loc[1]+hh), (0, 0, 255), 2)\n",
    "                img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] = \\\n",
    "                    img_alpha[max_loc[1]: max_loc[1]+hh, max_loc[0]: max_loc[0]+ww] - alpha_template / 255.0\n",
    "\n",
    "                # write black circle at max_loc in corr_img\n",
    "                cv2.circle(blur, (max_loc), radius=rad, color=0, thickness=cv2.FILLED)\n",
    "                count += 1\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        img_alpha_c = img_alpha.clip(0, 1).astype(np.uint8)\n",
    "        mask = cv2.merge([img_alpha_c, img_alpha_c, img_alpha_c]).astype(np.uint8)\n",
    "        # result = cv2.multiply(resized, mask)\n",
    "        # cv2.imwrite('./cloud/alpha_%.2f.png' % scale, result)\n",
    "        # cv2.imwrite('./cloud/blur_blocked_%.2f.png' % scale, blur)\n",
    "        alpha_area = np.sum(img_alpha_c == 0) / (img_alpha_c.shape[0] * img_alpha_c.shape[1])\n",
    "        # print(\"scale %.2f: %d, %.2f, %d, %.4f\" % (scale, maximum, maximum / (scale), count, alpha_area))\n",
    "        result_set.append([scale, maximum, maximum / scale, count, alpha_area, mask])\n",
    "    selected_scaling = sorted(result_set, key=lambda x: -x[2])[0]\n",
    "    print(selected_scaling[:5])\n",
    "    resized_original = cv2.resize(selected_scaling[5], (img.shape[1], img.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    # return resized_original\n",
    "\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png'\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/2a0de14a-c3dc-4d6f-b1ee-b9a42be4725d.png'\n",
    "files = ['1c3f544e-dc6c-4aff-b6cd-ac5408439269']\n",
    "channel_name = 'ps11w4-winterstorms_plague-e99769'\n",
    "\n",
    "img = cv2.imread(path)\n",
    "without_cloud = remove_clouds(img)\n",
    "print(img.shape, without_cloud.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob(scale, blur):\n",
    "\t# img_gray = cv2.imread('./cloud/blur_%.2f.png' % scale, cv2.IMREAD_GRAYSCALE)\n",
    "\t# keypoints = detector.detect(img_gray)\n",
    "\t# print(keypoints[0])\n",
    "\t# im_with_keypoints = cv2.drawKeypoints(img_gray, keypoints, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\t# blobs('./cloud/blur_%.2f.png' % scale)\n",
    "\t# cv2.imwrite('./cloud/blobs_%.2f.png' % scale, im_with_keypoints)\n",
    "\tthresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "\tcv2.imwrite('./cloud/thresh_%.2f.png' % scale, thresh)\n",
    "\toutput = cv2.connectedComponentsWithStats(thresh, 4, cv2.CV_32S)\n",
    "\t(numLabels, labels, stats, centroids) = output\n",
    "\tsum_mask = np.zeros_like(thresh)\n",
    "\n",
    "\tfor i in range(0, numLabels):\n",
    "\t\tmask = (labels == i).astype(\"uint8\") * 255\n",
    "\t\tif np.sum(mask) > 2 and np.sum(mask) < 1000:\n",
    "\t\t\tsum_mask = (sum_mask + mask).clip(0, 255)\n",
    "\t\t\n",
    "\tcv2.imwrite('./cloud/blobs_%.2f.png' % (scale), sum_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "# Read the main image\n",
    "path = '/Users/jean/Documents/Coding/Polytopia/src/resources/ps11w4-winterstorms_plague-e99769/INPUT/1c3f544e-dc6c-4aff-b6cd-ac5408439269.png'\n",
    "img_rgb = cv2.imread(path)\n",
    "  \n",
    "# Convert to grayscale\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Read the template\n",
    "template = cv2.imread('/Users/jean/Documents/Coding/Polytopia/src/templates/cloud_template.png',0)\n",
    "  \n",
    "# Store width and height of template in w and h\n",
    "w, h = template.shape[::-1]\n",
    "found = None\n",
    " \n",
    "for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    " \n",
    "    # resize the image according to the scale, and keep track\n",
    "    # of the ratio of the resizing\n",
    "    new_dim = (int(img_gray.shape[1] * scale), int(image.shape[0] * scale))\n",
    "    resized = cv2.resize(img_gray, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    r = img_gray.shape[1] / float(resized.shape[1])\n",
    "  \n",
    "    # detect edges in the resized, grayscale image and apply template\n",
    "    # matching to find the template in the image \n",
    "    edged = cv2.Canny(resized, 50, 200) \n",
    "    result = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF)\n",
    "    (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)\n",
    "    # if we have found a new maximum correlation value, then update\n",
    "    # the found variable if found is None or maxVal > found[0]:\n",
    "    if resized.shape[0] < h or resized.shape[1] < w:\n",
    "        break\n",
    "    found = (maxVal, maxLoc, r)\n",
    "  \n",
    "# unpack the found variable and compute the (x, y) coordinates\n",
    "# of the bounding box based on the resized ratio\n",
    "(_, maxLoc, r) = found\n",
    "(startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "(endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    " \n",
    "# draw a bounding box around the detected result and display the image\n",
    "cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "from score_recognition import score_recognition_utils\n",
    "\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/tests/resources/score_recognition/image_3.png\"\n",
    "path = \"/Users/jean/Documents/Coding/Polytopia/Screenshot_20220210_233213_air.com.midjiwan.polytopia.jpg\"\n",
    "image = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = score_recognition_utils.read_scores(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "import numpy as np\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "light = (256, 256, 256)\n",
    "dark = (100, 0, 100)\n",
    "#dark = (120, 0, 50)\n",
    "#light = (230, 40, 150)\n",
    "\n",
    "# light = (255, 255, 255)\n",
    "# dark = (150, 150, 150)\n",
    "light = (200, 256, 256)\n",
    "dark = (0, 210, 200)\n",
    "\n",
    "mask = cv2.inRange(hsv, dark, light)\n",
    "print(np.min(mask), np.max(mask))\n",
    "cv2.imwrite('./mask.png', mask)\n",
    "result = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imwrite('./colour.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert = cv2.invert(image)\n",
    "img_not = cv2.bitwise_not(image)\n",
    "cv2.imwrite('./inverted.png', img_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = score_recognition_utils.get_scores(img_not, only_you=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scores = pd.DataFrame([\n",
    "[None, 0, 415],\n",
    "['Player1', 0, 640],\n",
    "[None, 0, 465],\n",
    "[None, 0, 630],\n",
    "[None, 1, 760],\n",
    "['Npico', 1, 640],\n",
    "['Player1', 1, 940],\n",
    "[None, 1, 790],\n",
    "[None, 2, 1515],\n",
    "['Npico', 2, 1240],\n",
    "['Nuupi', 2, 1530],\n",
    "['Player1', 2, 2035]], columns=['polytopia_player_name', 'turn', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_recognition import score_visualisation\n",
    "print(score_visualisation.print_scores(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_visualisation.print_player_scores(scores, 'Player1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from table2ascii import table2ascii as t2a, PresetStyle\n",
    "\n",
    "print(list(scores.columns))\n",
    "# In your command:\n",
    "output = t2a(\n",
    "    header=list(scores.columns), # [\"Rank\", \"Team\", \"Kills\", \"Position Pts\", \"Total\"],\n",
    "    body=scores.to_numpy().tolist(), # [[1, 'Team A', 2, 4, 6], [2, 'Team B', 3, 3, 6], [3, 'Team C', 4, 2, 6]],\n",
    "    style=PresetStyle.thin_compact\n",
    ")\n",
    "print(output)\n",
    "# await ctx.send(f\"```\\n{output}\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.loc[scores[\"polytopia_player_name\"].notna(), 'delta'] = scores[scores[\"polytopia_player_name\"].notna()].groupby('polytopia_player_name').apply(lambda x: x['score'].astype(int).diff()).values\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
